{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports",
   "id": "4e577352b8e10aa3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-01T17:37:20.194487Z",
     "start_time": "2025-07-01T17:37:15.678885Z"
    }
   },
   "source": [
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from extratorFeatures import *\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import os\n",
    "from collections import deque\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Modelo IA",
   "id": "5ece991f9317e0de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T22:51:06.118727Z",
     "start_time": "2025-06-28T22:51:06.105883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. Dataset ---\n",
    "\n",
    "def carregar_dataset_features(caminho_arquivo_h5):\n",
    "    \"\"\"Carrega as features (X) e os rótulos (y) de um arquivo HDF5.\"\"\"\n",
    "    try:\n",
    "        with h5py.File(caminho_arquivo_h5, 'r') as hf:\n",
    "            X = hf['features'][:]\n",
    "            y = hf['labels'][:]\n",
    "        return X, y\n",
    "    except (FileNotFoundError, KeyError) as e:\n",
    "        print(f\"Erro ao carregar o dataset '{caminho_arquivo_h5}': {e}\")\n",
    "        return None, None\n",
    "\n",
    "def initDataset(dataset_path):\n",
    "    \"\"\"Carrega e pré-processa os dados, retornando o normalizador (scaler).\"\"\"\n",
    "    X_data, y_data = carregar_dataset_features(dataset_path)\n",
    "    if X_data is None:\n",
    "        return None, None, None\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_data)\n",
    "    X_final = X_scaled.T\n",
    "    y_final = y_data.reshape(1, y_data.shape[0])\n",
    "    return X_final, y_final, scaler\n",
    "\n",
    "# --- 2. Regressão Logística ---\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0.0\n",
    "    return w, b\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    epsilon = 1e-15\n",
    "    cost = (-1/m) * np.sum(Y * np.log(A + epsilon) + (1 - Y) * np.log(1 - A + epsilon))\n",
    "    dw = (1/m) * np.dot(X, (A - Y).T)\n",
    "    db = (1/m) * np.sum(A - Y)\n",
    "    return {\"dw\": dw, \"db\": db}, np.squeeze(cost)\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        w = w - learning_rate * grads[\"dw\"]\n",
    "        b = b - learning_rate * grads[\"db\"]\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            if print_cost:\n",
    "                print(f\"Custo após iteração {i}: {cost}\")\n",
    "    return {\"w\": w, \"b\": b}, grads, costs\n",
    "\n",
    "def predict(w, b, X):\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    return (A > 0.5) * 1\n",
    "\n",
    "def predict_prob(w, b, X): return sigmoid(np.dot(w.T, X) + b)\n",
    "\n",
    "def model(dataset_path, num_iterations=3000, learning_rate=0.01, print_cost=True):\n",
    "    \"\"\"Constrói, treina e retorna o modelo completo.\"\"\"\n",
    "    X_train, Y_train, scaler = initDataset(dataset_path)\n",
    "    if X_train is None: return None\n",
    "\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "    parameters, _, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "\n",
    "    Y_prediction_train = predict(parameters[\"w\"], parameters[\"b\"], X_train)\n",
    "    train_accuracy = 100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100\n",
    "    print(f\"\\nAcurácia no conjunto de treino: {train_accuracy:.2f} %\")\n",
    "\n",
    "    return {\n",
    "        \"costs\": costs, \"w\": parameters[\"w\"], \"b\": parameters[\"b\"],\n",
    "        \"scaler\": scaler, \"train_accuracy\": train_accuracy\n",
    "    }\n",
    "\n",
    "# --- 3. Funções de Teste e Validação ---\n",
    "\n",
    "def calcular_precisao_dataset(dataset_path, model_results):\n",
    "    \"\"\"Calcula a acurácia do modelo em um novo dataset.\"\"\"\n",
    "    if \"scaler\" not in model_results:\n",
    "        print(\"Erro: 'scaler' não encontrado.\")\n",
    "        return\n",
    "\n",
    "    w, b, scaler = model_results[\"w\"], model_results[\"b\"], model_results[\"scaler\"]\n",
    "    X_test_data, Y_test_data = carregar_dataset_features(dataset_path)\n",
    "    if X_test_data is None: return\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test_data)\n",
    "    Y_prediction_test = predict(w, b, X_test_scaled.T)\n",
    "    test_accuracy = 100 - np.mean(np.abs(Y_prediction_test - Y_test_data.reshape(1, -1))) * 100\n",
    "    print(f\"Acurácia no dataset '{dataset_path}': {test_accuracy:.2f} %\")\n",
    "    return test_accuracy"
   ],
   "id": "1fbda51a4ef1f7ca",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "d = model(\"Datasets/dataset_features.h5\", num_iterations = 50000, learning_rate = 0.005, print_cost = True)",
   "id": "7b9398cca2fc9594",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testes com videos com multithreading",
   "id": "d9e05517ad2e5497"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T23:07:07.379887Z",
     "start_time": "2025-06-28T23:07:07.368930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reader_thread(video_path, raw_frames_queue, stop_event):\n",
    "    \"\"\"\n",
    "    Thread 1: Leitora de Vídeo\n",
    "    - Apenas lê os frames do arquivo de vídeo.\n",
    "    - Coloca os frames brutos em uma fila (raw_frames_queue).\n",
    "    - Isola o gargalo de I/O.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Thread Leitora iniciada.\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Erro: Não foi possível abrir o vídeo em '{video_path}'\")\n",
    "        stop_event.set()\n",
    "        return\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        if raw_frames_queue.full():\n",
    "            # Se a fila estiver cheia, espera um pouco para não consumir toda a memória\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            # Fim do vídeo\n",
    "            print(\"[INFO] Fim do vídeo. Sinalizando para threads terminarem.\")\n",
    "            stop_event.set()\n",
    "            break\n",
    "\n",
    "        raw_frames_queue.put(frame)\n",
    "\n",
    "    cap.release()\n",
    "    print(\"[INFO] Thread Leitora finalizada.\")\n",
    "\n",
    "\n",
    "def processor_thread(raw_frames_queue, processed_frames_queue, model_results, stop_event, LARGURA_PROCESSAMENTO=640):\n",
    "    \"\"\"\n",
    "    Thread 2: Processadora de Frames\n",
    "    - Pega um frame da fila de frames brutos.\n",
    "    - Realiza todo o processamento pesado (redimensionamento, detecção, inferência).\n",
    "    - Desenha os resultados no frame.\n",
    "    - Coloca o frame processado na fila de frames processados.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Thread Processadora iniciada.\")\n",
    "    w, b, scaler = model_results[\"w\"], model_results[\"b\"], model_results[\"scaler\"]\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        try:\n",
    "            frame = raw_frames_queue.get(timeout=1)\n",
    "        except queue.Empty:\n",
    "            if stop_event.is_set():\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        altura_original, largura_original = frame.shape[:2]\n",
    "        fator_escala = LARGURA_PROCESSAMENTO / largura_original\n",
    "        nova_altura = int(altura_original * fator_escala)\n",
    "        frame_processado = cv2.resize(frame, (LARGURA_PROCESSAMENTO, nova_altura), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        contornos, img_hsv = extrair_contornos(frame_processado)\n",
    "\n",
    "        if contornos:\n",
    "            for contorno in contornos:\n",
    "                features = extrair_features(img_hsv, contorno)\n",
    "\n",
    "                if features is not None:\n",
    "                    features_scaled = scaler.transform(features.reshape(1, -1))\n",
    "                    prob = sigmoid(np.dot(w.T, features_scaled.T) + b)[0, 0]\n",
    "\n",
    "                    if prob > 0.6:  # Limiar de decisão\n",
    "                        color = (0, 0, 255)  # Vermelho\n",
    "\n",
    "                        contorno_original = (contorno / fator_escala).astype(np.int32)\n",
    "                        cv2.drawContours(frame, [contorno_original], -1, color, 2)\n",
    "\n",
    "                        (x, y, _, _) = cv2.boundingRect(contorno_original)\n",
    "                        cv2.putText(frame, f\"{prob:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Coloca o frame (com ou sem detecções) na fila de exibição\n",
    "        if not processed_frames_queue.full():\n",
    "            processed_frames_queue.put(frame)\n",
    "\n",
    "    print(\"[INFO] Thread Processadora finalizada.\")\n",
    "\n",
    "\n",
    "def testar_video(video_path, model_results):\n",
    "    \"\"\"\n",
    "    Thread Principal Otimizada: Exibição com FPS estável.\n",
    "    - Desacopla a taxa de exibição da taxa de processamento.\n",
    "    - Sempre exibe o frame mais recente disponível a uma taxa de quadros alvo.\n",
    "    - Adiciona um contador de FPS para visualização.\n",
    "    \"\"\"\n",
    "    # Filas e evento de parada (mesma configuração de antes)\n",
    "    raw_frames_queue = queue.Queue(maxsize=10)\n",
    "    processed_frames_queue = queue.Queue(maxsize=10)\n",
    "    stop_event = threading.Event()\n",
    "\n",
    "    # --- Criação e início das threads (mesma configuração de antes) ---\n",
    "    reader = threading.Thread(target=reader_thread, args=(video_path, raw_frames_queue, stop_event))\n",
    "    processor = threading.Thread(target=processor_thread, args=(raw_frames_queue, processed_frames_queue, model_results, stop_event))\n",
    "    reader.daemon = True\n",
    "    processor.daemon = True\n",
    "    reader.start()\n",
    "    processor.start()\n",
    "\n",
    "    TARGET_FPS = 30.0\n",
    "    TARGET_FRAME_TIME = 1.0 / TARGET_FPS\n",
    "\n",
    "    fps_calculator = deque(maxlen=int(TARGET_FPS))\n",
    "\n",
    "    latest_frame = None\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        frame_start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            temp_frame = None\n",
    "            while True:\n",
    "                temp_frame = processed_frames_queue.get_nowait()\n",
    "                # Se um novo frame foi pego, atualiza a variável\n",
    "                if temp_frame is not None:\n",
    "                    latest_frame = temp_frame\n",
    "        except queue.Empty:\n",
    "            # Fila vazia, continua com o último frame que tínhamos\n",
    "            pass\n",
    "\n",
    "        if latest_frame is not None:\n",
    "            fps_calculator.append(frame_start_time)\n",
    "\n",
    "            # Calcula o FPS com base nos timestamps\n",
    "            if len(fps_calculator) > 1:\n",
    "                time_diff = fps_calculator[-1] - fps_calculator[0]\n",
    "                current_fps = len(fps_calculator) / time_diff if time_diff > 0 else 0.0\n",
    "                cv2.putText(latest_frame, f\"Display FPS: {current_fps:.1f}\",\n",
    "                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow('Teste em Video Multithread - FPS Estavel', latest_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"[INFO] Tecla 'q' pressionada. Encerrando...\")\n",
    "            stop_event.set()\n",
    "            break\n",
    "\n",
    "        # Garantir a taxa de quadros ---\n",
    "        elapsed_time = time.time() - frame_start_time\n",
    "        sleep_time = TARGET_FRAME_TIME - elapsed_time\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "        if not reader.is_alive() and processed_frames_queue.empty():\n",
    "             break\n",
    "\n",
    "    reader.join(timeout=1)\n",
    "    processor.join(timeout=1)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[INFO] Aplicação encerrada.\")"
   ],
   "id": "31eaabe58bba6eb6",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T22:33:19.476562Z",
     "start_time": "2025-06-28T22:33:19.148674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testar_video(\"Videos/Normal/Normal1.mp4\", d)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "49ab69354ab0d471",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao abrir vídeo: 'video/Normal/Normal2.mp4'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T23:07:51.267985Z",
     "start_time": "2025-06-28T23:07:10.871356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testar_video(\"Videos/Fire/Fire1.mp4\", d)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "e3ef3ab182db144d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Thread Leitora iniciada.\n",
      "[INFO] Thread Processadora iniciada.\n",
      "[INFO] Fim do vídeo. Sinalizando para threads terminarem.\n",
      "[INFO] Thread Leitora finalizada.\n",
      "[INFO] Thread Processadora finalizada.\n",
      "[INFO] Aplicação encerrada.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save e Load do modelo treinado",
   "id": "ef8ee2b102b80656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T22:45:20.317989Z",
     "start_time": "2025-06-28T22:45:20.311371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def salvar_modelo(model_results, caminho_arquivo):\n",
    "    \"\"\"\n",
    "    Salva os componentes essenciais do modelo treinado em um arquivo usando pickle.\n",
    "\n",
    "    Args:\n",
    "        model_results (dict): Dicionário contendo 'w', 'b', e 'scaler'.\n",
    "        caminho_arquivo (str): Caminho para salvar o arquivo do modelo (ex: 'modelo.pkl').\n",
    "    \"\"\"\n",
    "    # Extrai apenas os componentes necessários para a previsão\n",
    "    modelo_para_salvar = {\n",
    "        'w': model_results['w'],\n",
    "        'b': model_results['b'],\n",
    "        'scaler': model_results['scaler']\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(caminho_arquivo, 'wb') as f:\n",
    "            pickle.dump(modelo_para_salvar, f)\n",
    "        print(f\"Modelo salvo com sucesso em '{caminho_arquivo}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o modelo: {e}\")\n",
    "\n",
    "def carregar_modelo(caminho_arquivo):\n",
    "    \"\"\"\n",
    "    Carrega um modelo treinado de um arquivo pickle.\n",
    "\n",
    "    Args:\n",
    "        caminho_arquivo (str): Caminho do arquivo do modelo a ser carregado.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário contendo 'w', 'b', e 'scaler', ou None se falhar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(caminho_arquivo, 'rb') as f:\n",
    "            model_results = pickle.load(f)\n",
    "        print(f\"Modelo carregado com sucesso de '{caminho_arquivo}'\")\n",
    "        return model_results\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo do modelo não encontrado em '{caminho_arquivo}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o modelo: {e}\")\n",
    "        return None\n"
   ],
   "id": "d2b2e0cdd9b44afa",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "salvar_modelo(d, \"Modelos/modelo_features\")",
   "id": "ec8a160ee8bf2ec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T22:45:41.520313Z",
     "start_time": "2025-06-28T22:45:41.513292Z"
    }
   },
   "cell_type": "code",
   "source": "d = carregar_modelo(\"Modelos/modelo_features\")",
   "id": "2d9940335ec78a8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso de 'Modelos/modelo_features'\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
